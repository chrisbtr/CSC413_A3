{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZDsDHiGqKjL",
        "outputId": "6da6c699-546c-4bc7-d891-203f190d7873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from pretty_midi) (1.22.4)\n",
            "Collecting mido>=1.1.16\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from pretty_midi) (1.16.0)\n",
            "Building wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592303 sha256=35590232a2353e68b1e5932d90f18278036c7a85f5bc4ef58c27513977a8a9a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/ec/20/b8e937a5bcf1de547ea5ce465db7de7f6761e15e6f0a01e25f\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: mido, pretty_midi\n",
            "Successfully installed mido-1.2.10 pretty_midi-0.2.10\n"
          ]
        }
      ],
      "source": [
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "path_to_data = '/content/gdrive/My Drive/University/Year 4/CSC413/Project/data.pickle'\n",
        "\n",
        "!pip install pretty_midi\n",
        "!cp \"/content/gdrive/My Drive/University/Year 4/CSC413/Project/data_parser.py\" .\n",
        "\n",
        "from data_parser import create_midi_file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "NdkLToGQqYSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MusicGenRNN(nn.Module):\n",
        "  def __init__(self, hidden_size = 512, num_rnn_layers = 1, bias_rnn = True, pitch_embedding_size=130):\n",
        "    super(MusicGenRNN, self).__init__()\n",
        "    # pitch_vocab_size = number of notes possible + begin sequence token\n",
        "    self.pitch_vocab_size = 128 + 1\n",
        "    # to turn pitch to one hots\n",
        "    self.ident = torch.eye(self.pitch_vocab_size).to(device)\n",
        "\n",
        "    # number of units in RNN encoder\n",
        "    self.hidden_size = hidden_size\n",
        "    \n",
        "    # embedding size for pitch, to turn one hots to continous vectors\n",
        "    self.pitch_embedding_size = pitch_embedding_size\n",
        "    self.pitch_embedding_layer = nn.Linear(self.pitch_vocab_size, self.pitch_embedding_size, bias=False)\n",
        "    \n",
        "    # LSTM params nn.LSTM(input_size, hidden_size, num_layers, bias, batch_first=True, dropout)\n",
        "    # add two to embedding size to account for step and duration\n",
        "    self.rnn = nn.LSTM(self.pitch_embedding_size + 2, hidden_size, num_rnn_layers, bias=bias_rnn, batch_first=True, dropout=0)\n",
        "    \n",
        "    # decoders to get distributions and values for pitch, step and duration\n",
        "    # went with 300 here as it is in between deafult 512 and pitch_vocab_size\n",
        "    self.decoder_pitch1 = nn.Linear(hidden_size, 300)\n",
        "    self.decoder_pitch2 = nn.Linear(300, self.pitch_vocab_size)\n",
        "\n",
        "    # step and duration decoders\n",
        "    self.decoder_step = nn.Linear(hidden_size, 1)\n",
        "    self.decoder_duration = nn.Linear(hidden_size, 1)\n",
        "\n",
        "\n",
        "  def forward(self, input, hidden_in=None):\n",
        "    # parse input\n",
        "    pitch_in = input[:, :, 0].long()\n",
        "    step_in = input[:, :, 1]\n",
        "    dur_in = input[:, :, 2]\n",
        "    # embed pitch\n",
        "    pitch_one_hot = self.ident[pitch_in]\n",
        "    pitch_emb = self.pitch_embedding_layer(pitch_one_hot)\n",
        "    # join everything back together to encode it\n",
        "    inp = torch.concat((pitch_emb, step_in.unsqueeze(2), dur_in.unsqueeze(2)), dim=2)\n",
        "    output, hidden_out = self.rnn(inp, hidden_in) \n",
        "    # decoder everything\n",
        "    out_pitch = self.decoder_pitch2(torch.relu(self.decoder_pitch1(output)))  \n",
        "    out_step = self.decoder_step(output)\n",
        "    out_dur = self.decoder_duration(output)\n",
        "\n",
        "    return torch.concat((out_pitch, out_step, out_dur), dim=2), hidden_out"
      ],
      "metadata": {
        "id": "Gi5bsggAqYEM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Data**"
      ],
      "metadata": {
        "id": "eZd4xBWWsC1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path_to_data, 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "\n",
        "train_set, validation_set, test_set = dataset\n",
        "\n",
        "print(train_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkuRFdiosVPs",
        "outputId": "7c789ffa-107c-49ff-eb88-a3613f2ee51b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3603, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "86530rzKsVyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_distros = []\n",
        "valid_distros = []\n",
        "\n",
        "def train(model, device, train_data, valid_data, batch_size=32, weight_decay=0.0,\n",
        "           learning_rate=0.001, num_epochs=7, checkpoint_path=None):\n",
        "  # get loss function, CE has softmax built in\n",
        "  criterion_pitch = nn.CrossEntropyLoss()\n",
        "  criterion_step = nn.MSELoss()\n",
        "  criterion_dur = nn.MSELoss()\n",
        "  # criterion_step = nn.L1Loss()\n",
        "  # criterion_dur = nn.L1Loss()\n",
        "\n",
        "  # get optimizer\n",
        "  optimizer = optim.Adam(model.parameters(),\n",
        "                          lr=learning_rate,\n",
        "                          weight_decay=weight_decay)\n",
        "  \n",
        "  # get dataloader, load training data, and validation data\n",
        "  train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True)\n",
        "  validation_loader = torch.utils.data.DataLoader(valid_data,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True)\n",
        "  \n",
        "  # learning curve information for plotting\n",
        "  train_iters_list, losses_training, iter_at_epoch, train_acc, val_acc = [], [], [], [], []\n",
        "  valid_iters_list, losses_validation =  [], []\n",
        "  num_iters_train, num_iters_valid = 0, 0\n",
        "\n",
        "  # iterate the given number of epochs\n",
        "  for epoch in range(num_epochs):\n",
        "    # shuffling data done automatically by data loader\n",
        "    for batch_of_sequences in iter(train_loader): # iterate through all data in train loader\n",
        "    # batch_of_sequences is of batch size\n",
        "      # account for smaller last batch\n",
        "      if batch_of_sequences.size()[0] < batch_size:\n",
        "        continue\n",
        "\n",
        "      # compute forward and backward pass\n",
        "      model.train() # ensure model in train mode\n",
        "\n",
        "      # add <BOS>=128, pitch values range 0-127 inclusive\n",
        "      BOS = torch.tensor([128, 0.0, 0.0] * batch_size).reshape(batch_size, 1, 3)\n",
        "      input = torch.concat((BOS, batch_of_sequences), dim=1).to(device)\n",
        "      # only go up to second last input as last one is just predicted never fed in\n",
        "      input = input[:, :-1, :] \n",
        "      out, _ = model(input.float())\n",
        "      out_pitch = out[:, :, :129]\n",
        "      out_step = out[:, :, 129]\n",
        "      out_dur = out[:, :, 130]\n",
        "\n",
        "      targets = batch_of_sequences.float().to(device)\n",
        "      targets_pitch = targets[:, :, 0].long()\n",
        "      targets_step = targets[:, :, 1]\n",
        "      targets_dur = targets[:, :, 2]\n",
        "      \n",
        "      # compute losses\n",
        "      loss_pitch = criterion_pitch(out_pitch.reshape(-1, model.pitch_vocab_size), targets_pitch.reshape(-1).long())\n",
        "      loss_step = criterion_step(out_step, targets_step)\n",
        "      loss_dur = criterion_dur(out_dur, targets_dur)\n",
        "      total_loss = loss_step + loss_dur + loss_pitch\n",
        "      # go backward/grad descent\n",
        "      total_loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # gather plotting data\n",
        "      num_iters_train += 1\n",
        "      losses_training.append(float(loss_pitch.item() + loss_step.item() + loss_dur.item()))\n",
        "      train_iters_list.append(num_iters_train)\n",
        "\n",
        "  \n",
        "    # iterate through all data in valid loader\n",
        "    for batch_of_sequences in iter(validation_loader): \n",
        "      # batch_of_sequences is of batch size\n",
        "        # account for smaller last batch\n",
        "        if batch_of_sequences.size()[0] < batch_size:\n",
        "          continue\n",
        "        # compute forward and backward pass\n",
        "        model.eval() # ensure model in eval mode, no decent here just trying to gain accuarcy\n",
        "\n",
        "        # add <BOS>=128, pitch values range 0-127 inclusive\n",
        "        BOS = torch.tensor([128, 0.0, 0.0] * batch_size).reshape(batch_size, 1, 3)\n",
        "        input = torch.concat((BOS, batch_of_sequences), dim=1).to(device)\n",
        "        # only go up to second last input as last one is just predicted never fed in\n",
        "        input = input[:, :-1, :] \n",
        "        out, _ = model(input.float())\n",
        "        out_pitch = out[:, :, :129]\n",
        "        out_step = out[:, :, 129]\n",
        "        out_dur = out[:, :, 130]\n",
        "\n",
        "        targets = batch_of_sequences.float().to(device)\n",
        "        targets_pitch = targets[:, :, 0].long()\n",
        "        targets_step = targets[:, :, 1]\n",
        "        targets_dur = targets[:, :, 2]\n",
        "        \n",
        "        # compute losses\n",
        "        loss_pitch_v = criterion_pitch(out_pitch.reshape(-1, model.pitch_vocab_size), targets_pitch.reshape(-1).long())\n",
        "        loss_step_v = criterion_step(out_step, targets_step)\n",
        "        loss_dur_v = criterion_dur(out_dur, targets_dur)\n",
        "        total_loss_v = loss_pitch_v + loss_step_v + loss_dur_v\n",
        "        \n",
        "        # gather plotting data\n",
        "        num_iters_valid += 1\n",
        "        losses_validation.append(float(loss_pitch_v.item() + loss_step_v.item() + loss_dur_v.item()))\n",
        "        valid_iters_list.append(num_iters_valid)\n",
        "\n",
        "    # --- epoch ended ---\n",
        "    # check point model\n",
        "    if (checkpoint_path is not None) and num_iters_train > 0:\n",
        "      torch.save(model.state_dict(), checkpoint_path.format(num_iters_train))\n",
        "\n",
        "    # track learning curve info\n",
        "    iter_at_epoch.append(num_iters_train)\n",
        "    cur_train_acc, cur_val_acc = estimate_accuracy(model, train_data, valid_data, 50, compute_set_distros=(len(iter_at_epoch) == 1))\n",
        "    train_acc.append(np.array(cur_train_acc) * 100)\n",
        "    val_acc.append(np.array(cur_val_acc) * 100)\n",
        "\n",
        "    print(\"\"\"Epoch %d. Iter %d.  [Train Acc pitch %.0f%%, step %.0f%%, duration %.0f%%, Train Loss %f]\n",
        "                              [Valid Acc %.0f%%, step %.0f%%, duration %.0f%%, Valid Loss %f]\"\"\" %\n",
        "              (epoch, iter_at_epoch[-1], train_acc[-1][0], train_acc[-1][1], train_acc[-1][2],\n",
        "               float((loss_pitch + loss_step + loss_dur).cpu().detach().numpy()),\n",
        "               val_acc[-1][0], val_acc[-1][1], val_acc[-1][2],\n",
        "               float((loss_pitch_v + loss_step_v + loss_dur_v).cpu().detach().numpy())))\n",
        "  return train_iters_list, losses_training, valid_iters_list, losses_validation, iter_at_epoch, np.array(train_acc), np.array(val_acc)\n",
        "\n",
        "\n",
        "\n",
        "def plot_learning_curve(train_iters_list, losses_training, valid_iters_list, losses_validation, iter_at_epoch, train_acc, val_acc):\n",
        "    \"\"\"\n",
        "    Plot the learning curve.\n",
        "    \"\"\"\n",
        "    plt.title(\"Learning Curve: Train Loss per Iteration\")\n",
        "    plt.plot(train_iters_list, losses_training, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Learning Curve: Valid Loss per Iteration\")\n",
        "    plt.plot(valid_iters_list, losses_validation, label=\"Valid\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Learning Curve: Accuracy Pitch per Iteration\")\n",
        "    plt.plot(iter_at_epoch, train_acc[:, 0], label=\"Train\")\n",
        "    plt.plot(iter_at_epoch, val_acc[:, 0], label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Learning Curve: Accuracy Step per Iteration\")\n",
        "    plt.plot(iter_at_epoch, train_acc[:, 1], label=\"Train\")\n",
        "    plt.plot(iter_at_epoch, val_acc[:, 1], label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Learning Curve: Accuracy Duration per Iteration\")\n",
        "    plt.plot(iter_at_epoch, train_acc[:, 2], label=\"Train\")\n",
        "    plt.plot(iter_at_epoch, val_acc[:, 2], label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def estimate_accuracy(model, train_set, valid_set, num_samples, compute_set_distros):\n",
        "\n",
        "  # build histogram/distribtution of tokens over train and valid set\n",
        "  global train_distros\n",
        "  global valid_distros\n",
        "\n",
        "  if compute_set_distros:\n",
        "    train_pitch_histo = [0.0001] * 128\n",
        "    valid_pitch_histo = [0.0001] * 128\n",
        "\n",
        "    # discretize step and duration into bins \n",
        "    train_step_histo = [0.0001] * int((15 - 0) // 0.5)\n",
        "    valid_step_histo = [0.0001] * int((15 - 0) // 0.5)\n",
        "\n",
        "    train_dur_histo = [0.0001] * int((15 - 0) // 0.5)\n",
        "    valid_dur_histo = [0.0001] * int((15 - 0) // 0.5)\n",
        "\n",
        "    for sequence in train_set:\n",
        "      for token in sequence:\n",
        "        pitch, step, dur = token\n",
        "        train_pitch_histo[int(pitch)] += 1\n",
        "        # use min here to make sure long step or dur well over 3 ends up in upper bin\n",
        "        # use \"step // 0.2 if step > 0 else 0\" to ensure steps/dur < 0 end up in lowest bin\n",
        "        train_step_histo[min(int(step // 5 if step > 0 else 0), len(train_step_histo) - 1)] += 1\n",
        "        train_dur_histo[min(int(dur // 0.5 if step > 0 else 0), len(train_dur_histo) - 1)] += 1\n",
        "\n",
        "    for sequence in valid_set:\n",
        "      for token in sequence:\n",
        "        pitch, step, dur = token\n",
        "        valid_pitch_histo[int(pitch)] += 1\n",
        "        valid_step_histo[min(int(step // 5 if step > 0 else 0), len(valid_step_histo) - 1)] += 1\n",
        "        valid_dur_histo[min(int(dur // 0.5 if step > 0 else 0), len(valid_dur_histo) - 1)] += 1\n",
        "\n",
        "    # set globals so we don't need to compute this more then once\n",
        "    train_distros = [train_pitch_histo, train_step_histo, train_dur_histo] \n",
        "    valid_distros = [valid_pitch_histo, valid_step_histo, valid_dur_histo]\n",
        "    \n",
        "  else:\n",
        "    train_pitch_histo, train_step_histo, train_dur_histo = train_distros\n",
        "    valid_pitch_histo, valid_step_histo, valid_dur_histo = valid_distros\n",
        "\n",
        "  model_pitch_histo = [0.0001] * 128\n",
        "  model_step_histo = [0.0001] * int((15 - 0) // 0.5)\n",
        "  model_dur_histo = [0.0001] * int((15 - 0) // 0.5)\n",
        "\n",
        "  for _ in range(num_samples):\n",
        "    gen_seq = sample_sequence(model, max_len=100, temperature=0.8)\n",
        "    for token in gen_seq:\n",
        "      pitch, step, dur = token\n",
        "      model_pitch_histo[min(max(int(pitch), 0), len(model_pitch_histo) - 1)] += 1\n",
        "      model_step_histo[min(int(step // 5 if step > 0 else 0), len(model_step_histo) - 1)] += 1\n",
        "      model_dur_histo[min(int(dur // 0.5 if step > 0 else 0), len(model_dur_histo) - 1)] += 1\n",
        "  \n",
        "  # compute distro similarity using JSD as it is symmetric and bounded between 0 and 1\n",
        "  # https://medium.com/geekculture/techniques-to-measure-probability-distribution-similarity-9145678d68a6\n",
        "\n",
        "  # train_distro_similarity = (_jensen_shannon_divergence(model_pitch_histo, train_pitch_histo) + \n",
        "                            # _jensen_shannon_divergence(model_step_histo, train_step_histo) +\n",
        "                            # _jensen_shannon_divergence(model_dur_histo, train_dur_histo)) / 3\n",
        "  # valid_distro_similarity = (_jensen_shannon_divergence(model_pitch_histo, valid_pitch_histo) + \n",
        "                            # _jensen_shannon_divergence(model_step_histo, valid_step_histo) +\n",
        "                            # _jensen_shannon_divergence(model_dur_histo, valid_dur_histo)) / 3\n",
        "  # return train_distro_similarity, valid_distro_similarity\n",
        "  return [[_jensen_shannon_divergence(model_pitch_histo, train_pitch_histo),\n",
        "           _jensen_shannon_divergence(model_step_histo, train_step_histo),\n",
        "           _jensen_shannon_divergence(model_dur_histo, train_dur_histo)],\n",
        "           [_jensen_shannon_divergence(model_pitch_histo, valid_pitch_histo),\n",
        "            _jensen_shannon_divergence(model_step_histo, valid_step_histo),\n",
        "            _jensen_shannon_divergence(model_dur_histo, valid_dur_histo)]]\n",
        "\n",
        "\n",
        "def _kullback_leibler_divergence(p_probs, q_probs):  \n",
        "    kl_div = p_probs * (np.log(p_probs / q_probs) / np.log(2))\n",
        "    return np.sum(kl_div)\n",
        "\n",
        "def _jensen_shannon_divergence(distro_model, distro_set):\n",
        "    # make numpy arrays\n",
        "    distro_model = np.array(distro_model)\n",
        "    distro_set = np.array(distro_set)\n",
        "    # normalize both distros\n",
        "    distro_model = distro_model / distro_model.sum()\n",
        "    distro_set = distro_set / distro_set.sum()\n",
        "    # average them\n",
        "    avg_distro = (distro_model + distro_set) / 2\n",
        "    # return avg of KL(model_distro, avg) and KL(<valid/train>_distro, avg)\n",
        "    return (_kullback_leibler_divergence(distro_model, avg_distro) \n",
        "                + _kullback_leibler_divergence(distro_set, avg_distro)) / 2\n"
      ],
      "metadata": {
        "id": "gE_iFOLusaeG"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MusicGenRNN(num_rnn_layers=3)\n",
        "model.to(device)\n",
        "# check_point_path = \"/content/gdrive/My Drive/University/Year 4/CSC413/Project/check_pts/ckpt-{}.pk\"\n",
        "plot_data = train(model, device, train_set[:200], validation_set, num_epochs=60, batch_size=20, weight_decay=1e-5)\n",
        "plot_learning_curve(*plot_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WPNsjy8wqpY",
        "outputId": "eaa65701-b83d-4cb9-8e26-e28784970915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0. Iter 10.  [Train Acc pitch 9%, step 0%, duration 3%, Train Loss 4.464976]\n",
            "                              [Valid Acc 11%, step 0%, duration 3%, Valid Loss 4.015709]\n",
            "Epoch 1. Iter 20.  [Train Acc pitch 3%, step 0%, duration 3%, Train Loss 3.818893]\n",
            "                              [Valid Acc 4%, step 0%, duration 3%, Valid Loss 4.013306]\n",
            "Epoch 2. Iter 30.  [Train Acc pitch 2%, step 0%, duration 3%, Train Loss 3.881528]\n",
            "                              [Valid Acc 5%, step 0%, duration 3%, Valid Loss 4.094972]\n",
            "Epoch 3. Iter 40.  [Train Acc pitch 3%, step 0%, duration 3%, Train Loss 3.797316]\n",
            "                              [Valid Acc 5%, step 0%, duration 2%, Valid Loss 3.812119]\n",
            "Epoch 4. Iter 50.  [Train Acc pitch 2%, step 0%, duration 3%, Train Loss 3.883245]\n",
            "                              [Valid Acc 4%, step 0%, duration 3%, Valid Loss 4.095923]\n",
            "Epoch 5. Iter 60.  [Train Acc pitch 10%, step 0%, duration 36%, Train Loss 3.857367]\n",
            "                              [Valid Acc 10%, step 0%, duration 37%, Valid Loss 3.884047]\n",
            "Epoch 6. Iter 70.  [Train Acc pitch 12%, step 0%, duration 6%, Train Loss 3.651186]\n",
            "                              [Valid Acc 12%, step 0%, duration 7%, Valid Loss 3.693362]\n",
            "Epoch 7. Iter 80.  [Train Acc pitch 10%, step 0%, duration 3%, Train Loss 3.568334]\n",
            "                              [Valid Acc 10%, step 0%, duration 3%, Valid Loss 3.631839]\n",
            "Epoch 8. Iter 90.  [Train Acc pitch 2%, step 0%, duration 3%, Train Loss 3.484745]\n",
            "                              [Valid Acc 5%, step 0%, duration 2%, Valid Loss 3.624441]\n",
            "Epoch 9. Iter 100.  [Train Acc pitch 8%, step 0%, duration 3%, Train Loss 3.509620]\n",
            "                              [Valid Acc 12%, step 0%, duration 3%, Valid Loss 3.482995]\n",
            "Epoch 10. Iter 110.  [Train Acc pitch 1%, step 0%, duration 3%, Train Loss 3.328874]\n",
            "                              [Valid Acc 4%, step 0%, duration 3%, Valid Loss 3.313244]\n",
            "Epoch 11. Iter 120.  [Train Acc pitch 5%, step 0%, duration 3%, Train Loss 3.358559]\n",
            "                              [Valid Acc 9%, step 0%, duration 3%, Valid Loss 3.390159]\n",
            "Epoch 12. Iter 130.  [Train Acc pitch 3%, step 0%, duration 3%, Train Loss 3.424284]\n",
            "                              [Valid Acc 5%, step 0%, duration 3%, Valid Loss 3.717629]\n",
            "Epoch 13. Iter 140.  [Train Acc pitch 3%, step 0%, duration 3%, Train Loss 3.215163]\n",
            "                              [Valid Acc 6%, step 0%, duration 4%, Valid Loss 3.374687]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.load(\"/content/gdrive/My Drive/University/Year 4/CSC413/Project/friday_model_no_eos_more_data.pk\", map_location=torch.device('cpu'))\n",
        "model.load_state_dict(weights)\n",
        "# model.load_state_dict(torch.load(\"/content/gdrive/My Drive/University/Year 4/CSC413/Project/{}.pk\".format(NAME HERE)))"
      ],
      "metadata": {
        "id": "UACSM2Xzwyea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"/content/gdrive/My Drive/University/Year 4/CSC413/Project/{}.pk\".format(\"500-2enc-pre-of\"))"
      ],
      "metadata": {
        "id": "d_x5POF8x1Vn"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sampling/Producing Music**"
      ],
      "metadata": {
        "id": "emW8v0Gvwhe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_sequence(model, input_seq = None, max_len = 100, temperature = 0.8):\n",
        "  model.eval()\n",
        "  inp = torch.Tensor([[128, 0, 0]]).reshape(1,3).float().to(device)\n",
        "  generated_sequence = []\n",
        "  hidden = None\n",
        "  if input_seq is not None:\n",
        "    out, hidden = model(input_seq.unsqueeze(0), hidden)\n",
        "  for p in range(max_len):\n",
        "    output, hidden = model(inp.unsqueeze(0), hidden)\n",
        "\n",
        "    # Sample from the network as a multinomial distribution\n",
        "    output_dist = output[0, 0, :129].data.view(-1).div(temperature).exp()\n",
        "    top_i = int(torch.multinomial(output_dist, 1)[0])\n",
        "    # Add predicted character to string and use as next input \n",
        "    predicted_pitch = [top_i, output[0, 0, 129], output[0, 0, 130]]\n",
        "    if top_i == 129: break\n",
        "    generated_sequence.append(predicted_pitch)\n",
        "    inp = torch.Tensor([[top_i, output[0, 0, 129], output[0, 0, 130]]]).reshape(1, 3).float().to(device)\n",
        "    # print(inp)\n",
        "  if input_seq is not None:\n",
        "    return torch.concat((input_seq.cpu(), torch.tensor(generated_sequence).cpu()), dim=0)\n",
        "  return torch.tensor(generated_sequence)\n"
      ],
      "metadata": {
        "id": "8_G6zW5Zwg21"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = torch.Tensor(validation_set[50]).to(device)\n",
        "gen_seq = sample_sequence(model, max_len=200, temperature=.8, input_seq=inp)\n",
        "\n",
        "create_midi_file(\"/content/gdrive/My Drive/University/Year 4/CSC413/Project/currjj4.mid\", gen_seq)\n",
        "create_midi_file(\"/content/gdrive/My Drive/University/Year 4/CSC413/Project/test.mid\", inp)"
      ],
      "metadata": {
        "id": "prXFC_AGxxBl"
      },
      "execution_count": 55,
      "outputs": []
    }
  ]
}