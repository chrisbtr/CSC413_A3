{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5CYRKpOHv2ld"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "gaX60joVwRaT"
      },
      "outputs": [],
      "source": [
        "class MusicGenRNN(nn.Module):\n",
        "  def __init__(self, hidden_size=512, num_layers=1, bias=True):\n",
        "    super(MusicGenRNN, self).__init__()\n",
        "    # input # note, time and velocity \n",
        "    # size 128 note, 1, 128 velocity -> flatten to size of 128+1+128=257\n",
        "    self.one_hot_size = 128\n",
        "    self.note_emb_size = 128\n",
        "    self.velocity_emb_size = 128\n",
        "    self.input_size = self.note_emb_size + self.velocity_emb_size + 1\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = self.one_hot_size * 2 + 1\n",
        "\n",
        "    # identiy matrix for generating one-hot vectors\n",
        "    self.ident = torch.eye(self.one_hot_size) # recurrent neural network\n",
        "    self.note_embedding = nn.Linear(self.one_hot_size, self.note_emb_size, bias=False)\n",
        "    self.velocity_embedding = nn.Linear(self.one_hot_size, self.velocity_emb_size, bias=False)\n",
        "\n",
        "    #self.rnn = nn.LSTM(input_size, hidden_size, num_layers,bias, batch_first=True, dropout) # a fully-connect layer that outputs a distribution over\n",
        "                    # the next token, given the RNN output\n",
        "    self.rnn = nn.LSTM(self.input_size, hidden_size, num_layers, bias, batch_first=True, dropout=0)\n",
        "    self.decoder = nn.Linear(hidden_size, self.output_size)\n",
        "\n",
        "  def forward(self, input, hidden_in=None):\n",
        "    inp_note, inp_time, inp_velocity = input \n",
        "    inp_note = int(inp_note)\n",
        "    inp_velocity = int(inp_velocity)\n",
        "    one_hot_note = self.ident[inp_note] # generate one-hot vectors of input\n",
        "    one_hot_velocity = self.ident[inp_velocity]\n",
        "    embedded_note = self.note_embedding(one_hot_note)\n",
        "    embedded_velocity = self.velocity_embedding(one_hot_velocity)\n",
        "    inp = torch.concat((embedded_note.reshape(1, -1), torch.tensor([inp_time]).reshape(1, -1), embedded_velocity.reshape(1, -1)), dim=1)\n",
        "    output, hidden_out = self.rnn(inp, hidden_in) # get the next output and hidden state\n",
        "    output = self.decoder(output) # predict distribution over next tokens\n",
        "    return output, hidden_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[<torch.utils.data.dataset.Subset object at 0x0000028C23AEEE30>, <torch.utils.data.dataset.Subset object at 0x0000028C18BAFD90>, <torch.utils.data.dataset.Subset object at 0x0000028C18BAFE80>]\n"
          ]
        }
      ],
      "source": [
        "with open('data.pickle', 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "train, validation, test = dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0.3170733041666666, 0]\n",
            "torch.Size([2, 512])\n"
          ]
        }
      ],
      "source": [
        "model = MusicGenRNN(num_layers=2)\n",
        "print(train[0][0][31])\n",
        "\n",
        "t = torch.tensor(train[0][0][31])\n",
        "out, hidden = model(t)\n",
        "h_n, c_n = hidden\n",
        "print(c_n.shape)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "edf259275ad4a72d4dd5b452264ad5fb2b635233dff2a31edc6ebc740e55e21b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
