{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5CYRKpOHv2ld"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initial Model**"
      ],
      "metadata": {
        "id": "BtDg9WfT7Llm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MusicGenRNN(nn.Module):\n",
        "  def __init__(self, hidden_size=512, num_layers=1, bias=True):\n",
        "    super(MusicGenRNN, self).__init__()\n",
        "    # input # pitch, step and duration \n",
        "    # 128 is number of pitch possiblities\n",
        "    self.one_hot_size = 128 + 2 # account for <BOS> and <EOS> this will be the second last and last features of the one hot\n",
        "    self.pitch_embedding_size = 128 + 2\n",
        "    self.hidden_size = hidden_size\n",
        "    # size of embedding plus the 2 cts values step and duration\n",
        "    self.input_size = self.pitch_embedding_size + 2 \n",
        "    # size of discrete one hot plus the 2 cts values step and duration\n",
        "    self.output_size = self.one_hot_size + 2\n",
        "\n",
        "    # identiy matrix for generating one-hot vectors\n",
        "    self.ident = torch.eye(self.one_hot_size) \n",
        "    self.pitch_embedding = nn.Linear(self.one_hot_size, self.pitch_embedding_size, bias=False)\n",
        "\n",
        "    #self.rnn = nn.LSTM(input_size, hidden_size, num_layers, bias, batch_first=True, dropout)\n",
        "    self.rnn = nn.LSTM(self.input_size, hidden_size, num_layers, bias=bias, batch_first=True, dropout=0)\n",
        "    # a fully-connect layer that outputs a distribution over the next token, given the RNN output\n",
        "    self.decoder_pitch = nn.Linear(hidden_size, self.one_hot_size)\n",
        "    self.decoder_step = nn.Linear(hidden_size, 1)\n",
        "    self.decoder_duration = nn.Linear(hidden_size, 1)\n",
        "\n",
        "\n",
        "  def forward(self, input, hidden_in=None):\n",
        "    inp_pitch = input[:, :, 0]\n",
        "    inp_step = input[:, :, 1]\n",
        "    inp_duration = input[:, :, 2]\n",
        "    inp_pitch = inp_pitch.long()\n",
        "    # generate one-hot vector for discrete part of input\n",
        "    one_hot_pitch = self.ident[inp_pitch].float()\n",
        "    # embed the pitch to make it cts\n",
        "    embedded_pitch = self.pitch_embedding(one_hot_pitch)\n",
        "    # make inp = batch_size x sequence_length x 132\n",
        "    inp = torch.concat((embedded_pitch, inp_step.reshape(*inp_step.shape, 1), inp_duration.reshape(*inp_duration.shape, 1)), dim=2)\n",
        "    output, hidden_out = self.rnn(inp, hidden_in) # get the next output and hidden state\n",
        "    output_pitch = self.decoder_pitch(output) # predict distribution over next tokens\n",
        "    output_step = self.decoder_step(output) \n",
        "    output_duration = self.decoder_duration(output) \n",
        "    out = torch.concat((output_pitch, output_step.reshape(*inp_step.shape, 1), output_duration.reshape(*inp_duration.shape, 1)), dim=2)\n",
        "    return out, hidden_out"
      ],
      "metadata": {
        "id": "gaX60joVwRaT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Trainning Over Fitting**"
      ],
      "metadata": {
        "id": "XDX1DOWf5g1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "path_to_data = '/content/gdrive/My Drive/University/Year 4/CSC413/Project/data.pickle'\n",
        "\n",
        "with open(path_to_data, 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "\n",
        "train_set, validation_set, test_set = dataset\n",
        "\n",
        "print(train_set.shape)\n",
        "#print(train_set[0])\n",
        "\n",
        "# train contains N samples, of 64 length sequences, each sequence token is length 3.\n",
        "# token in sequence is [pitch, step, duration]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfFaAYG95ggF",
        "outputId": "c16f72a1-f208-43f2-a00c-70be19c72a32"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "(3603, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, valid_data, batch_size=32, weight_decay=0.0,\n",
        "           learning_rate=0.001, num_epochs=7, checkpoint_path=None):\n",
        "  # get loss function, CE has softmax built in\n",
        "  criterion_pitch = nn.CrossEntropyLoss()\n",
        "  criterion_step = nn.MSELoss()\n",
        "  criterion_duration = nn.MSELoss()\n",
        "  # get optimizer\n",
        "  optimizer = optim.Adam(model.parameters(),\n",
        "                          lr=learning_rate,\n",
        "                          weight_decay=weight_decay)\n",
        "  # get dataloader, load training data\n",
        "  train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True)\n",
        "  # get val loader\n",
        "  valid_loader = torch.utils.data.DataLoader(valid_data,\n",
        "                                               batch_size=batch_size,\n",
        "                                               shuffle=True)\n",
        "  # learning curve information for plotting\n",
        "  iters, iter_at_epoch, losses, train_acc, val_acc = [], [], [], [], []\n",
        "  num_iters = 0\n",
        "  # iterate the given number of epochs\n",
        "  for epoch in range(num_epochs):\n",
        "    # shuffling data done automatically by data loader\n",
        "    for batch_of_sequences in iter(train_loader): # iterate through all data in loader\n",
        "    # batch_of_sequences is of batch size\n",
        "      # account for smaller last batch\n",
        "      if batch_of_sequences.size()[0] < batch_size:\n",
        "        continue\n",
        "      # compute forward and backward pass\n",
        "      model.train() # ensute model in train mode\n",
        "\n",
        "      # add <BOS>=128 and <EOS>=129 terms, pitch values range 0-127 inclusive\n",
        "      BOS = torch.tensor([128, 0.0, 0.0] * batch_size).reshape(batch_size, 1, 3)\n",
        "      EOS = torch.tensor([129, 0.0, 0.0] * batch_size).reshape(batch_size, 1, 3)\n",
        "      # input shape is batch_size x seqeunce_length=64+1 x token size = 3\n",
        "      input = torch.concat((BOS, batch_of_sequences), dim=1) # <EOS> never input\n",
        "      input = input.to(device)\n",
        "      out, _ = model(input.float())\n",
        "      # out = batch_size x sequence_size x 132 [0-129 pitch probs, 130 step, 131 duration]\n",
        "      # 129 as it is the pitch tokens from 0-127 + 2 for <BOS> and <EOS>\n",
        "      out_pitch = out[:, :, 0:130]\n",
        "      out_step = out[:, :, 130]\n",
        "      out_duration = out[:, :, 131]\n",
        "      targets = torch.concat((batch_of_sequences, EOS), dim=1) # <BOS> never output\n",
        "      targets = targets.float()\n",
        "      targets_pitch = targets[:, :, 0]\n",
        "      targets_step = targets[:, :, 1]\n",
        "      targets_duration = targets[:, :, 2]\n",
        "      # shape must be batch_size x # classes=130 x sequence_length\n",
        "      loss_pitch = criterion_pitch(out_pitch.reshape(batch_size, -1, out_pitch.shape[1]), targets_pitch.long())\n",
        "      loss_step = criterion_step(out_step, targets_step)\n",
        "      loss_duration = criterion_duration(out_duration, targets_duration)\n",
        "      total_loss = loss_pitch + loss_step + loss_duration \n",
        "      total_loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      # gather plotting data\n",
        "      num_iters += 1\n",
        "      losses.append(float(total_loss) / batch_size)\n",
        "      iters.append(num_iters)\n",
        "\n",
        "    # ------------VALIDATE ----------\n",
        "    valid_losses , valid_iters = [], []\n",
        "    for batch_of_sequences in iter(valid_loader): # iterate through all data in loader\n",
        "    # batch_of_sequences is of batch size\n",
        "      # account for smaller last batch\n",
        "      if batch_of_sequences.size()[0] < batch_size:\n",
        "        continue\n",
        "      # compute forward and backward pass\n",
        "      model.eval() # ensute model in train mode\n",
        "\n",
        "      # add <BOS>=128 and <EOS>=129 terms, pitch values range 0-127 inclusive\n",
        "      BOS = torch.tensor([128, 0.0, 0.0] * batch_size).reshape(batch_size, 1, 3)\n",
        "      EOS = torch.tensor([129, 0.0, 0.0] * batch_size).reshape(batch_size, 1, 3)\n",
        "      # input shape is batch_size x seqeunce_length=64+1 x token size = 3\n",
        "      input = input.to(device)\n",
        "      input = torch.concat((BOS, batch_of_sequences), dim=1) # <EOS> never input\n",
        "      out, _ = model(input.float())\n",
        "      # out = batch_size x sequence_size x 132 [0-129 pitch probs, 130 step, 131 duration]\n",
        "      # 129 as it is the pitch tokens from 0-127 + 2 for <BOS> and <EOS>\n",
        "      out_pitch = out[:, :, 0:130]\n",
        "      out_step = out[:, :, 130]\n",
        "      out_duration = out[:, :, 131]\n",
        "      targets = torch.concat((batch_of_sequences, EOS), dim=1) # <BOS> never output\n",
        "      targets = targets.float()\n",
        "      targets_pitch = targets[:, :, 0]\n",
        "      targets_step = targets[:, :, 1]\n",
        "      targets_duration = targets[:, :, 2]\n",
        "      # shape must be batch_size x # classes=130 x sequence_length\n",
        "      loss_pitch = criterion_pitch(out_pitch.reshape(batch_size, -1, out_pitch.shape[1]), targets_pitch.long())\n",
        "      loss_step = criterion_step(out_step, targets_step)\n",
        "      loss_duration = criterion_duration(out_duration, targets_duration)\n",
        "      valid_total_loss = loss_pitch + loss_step + loss_duration \n",
        "      # gather plotting data\n",
        "      num_iters += 1\n",
        "      valid_losses.append(float(valid_total_loss) / batch_size)\n",
        "      valid_iters.append(num_iters)\n",
        "    # --- epoch ended ---\n",
        "    # # check point model\n",
        "    # if (checkpoint_path is not None) and num_iters > 0:\n",
        "    #   torch.save(model.state_dict(), checkpoint_path.format(num_iters))\n",
        "    # # track learning curve info\n",
        "    # iter_at_epoch.append(num_iters)\n",
        "    # train_acc.append(get_accuracy(model, train_data))\n",
        "    # val_acc.append(get_accuracy(model, valid_data))\n",
        "    # # report accuracies on train and validation set\n",
        "    print(\"Epoch %d. Iter %d. [Val Acc %.0f%%, Valid Loss %f] [Train Acc %.0f%%, Train Loss %f]\" %\n",
        "              (epoch, num_iters,0, float(valid_total_loss.detach().numpy()) ,0,float(total_loss.detach().numpy())))\n",
        "      # print(\"Epoch %d. Iter %d. [Val Acc %.0f%%] [Train Acc %.0f%%, Loss %f]\" % (epoch,\n",
        "      #     num_iters, val_acc[-1] * 100, train_acc[-1] * 100, float(total_loss.detach().numpy())))\n",
        "  return iters, losses, iter_at_epoch, train_acc, val_acc, valid_losses, valid_iters\n",
        "\n",
        "\n",
        "\n",
        "def plot_learning_curve(iters, losses, iter_at_epoch, train_accs, val_accs, valid_losses, valid_iters):\n",
        "    \"\"\"\n",
        "    Plot the learning curve.\n",
        "    \"\"\"\n",
        "    plt.title(\"Learning Curve: Loss per Iteration\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "    plt.title(\"Learning Curve: Valid Loss per Iteration\")\n",
        "    plt.plot(iters, losses, label=\"Valid\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "    plt.title(\"Learning Curve: Accuracy per Iteration\")\n",
        "    plt.plot(iter_at_epoch, train_accs, label=\"Train\")\n",
        "    plt.plot(iter_at_epoch, val_accs, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "IEBnkQH-AqdS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MusicGenRNN()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "plot_data = train(model, train_set, validation_set, num_epochs=120, batch_size=32)\n",
        "plot_learning_curve(*plot_data)\n"
      ],
      "metadata": {
        "id": "J4skpqviHJ_4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}